{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10035,"status":"ok","timestamp":1651286316526,"user":{"displayName":"Mohamed Magdy","userId":"08172732745582365979"},"user_tz":-120},"id":"WkmY7BCybkFG","outputId":"8195fe64-ef48-40fb-cf30-46f94f690f44"},"outputs":[],"source":["import os\n","import cv2\n","import math\n","import random\n","import numpy as np\n","import datetime as dt\n","import tensorflow as tf\n","import pathlib \n","import json\n","import imageio \n","import tensorflow as tf \n","import pandas as pd \n","import matplotlib.pyplot as plt\n","import tensorflow_hub as hub\n","from tqdm import tqdm\n","from moviepy.editor import  *\n","from collections import deque\n","%matplotlib inline\n","\n","from sklearn.model_selection import train_test_split\n","# Run imports\n","from official.vision.configs import video_classification\n","from official.projects.movinet.configs import movinet as movinet_configs\n","from official.projects.movinet.modeling import movinet\n","from official.projects.movinet.modeling import movinet_layers\n","from official.projects.movinet.modeling import movinet_model\n","from official.projects.movinet.tools import export_saved_model\n","from tfrecords import parse_example\n","\n","\n","\n","\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.utils import to_categorical\n","from tensorflow.keras.layers import *\n","from tensorflow.keras.callbacks import EarlyStopping\n","from tensorflow.keras.utils import plot_model"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["tf.test.gpu_device_name()\n","for gpu in tf.config.experimental.list_physical_devices(\"GPU\"):\n","    tf.config.experimental.set_virtual_device_configuration(gpu,[tf.config.experimental.VirtualDeviceConfiguration(memory_limit=2048)])\n","    "]},{"cell_type":"code","execution_count":3,"metadata":{"id":"2vYzP5pRbv3R"},"outputs":[],"source":["ss_files = pathlib.Path('.') # current path\n","\n","datafile_path = pathlib.Path('./')/'records/tfrecords' #records folder\n","datafile_path.mkdir(parents=True, exist_ok=True)\n","\n","\n","datafile_prefix = pathlib.Path('dataset/data')  #path to videos \n","\n","# we will save the files in the same place as our datafiles ()\n","tfrecords_save_path = datafile_path\n","train_path = tfrecords_save_path/'train/' # path to training shards \n","val_path = tfrecords_save_path/'val/' # path to val shards \n","test_path = tfrecords_save_path/'test/' # path to test shards \n"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":664,"status":"ok","timestamp":1651286317172,"user":{"displayName":"Mohamed Magdy","userId":"08172732745582365979"},"user_tz":-120},"id":"xLhj-iNZbvjl","outputId":"3dda3a4e-eba2-42f5-be19-ab6e581aa664"},"outputs":[],"source":["def get_shards(path):\n","    shards = [str(path) for path in path.iterdir() if '.tfrecord' == path.suffix]\n","    return shards\n","\n","train_shards=get_shards(train_path)\n","val_shards=get_shards(val_path)\n","test_shards=get_shards(test_path)\n"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"p2iRH0QObvSk"},"outputs":[],"source":["\n","# create dataset with train shards\n","# customize adding: .map(your_tf_function) after '.map(parse_example)\\'\n","# Note: sharding allows us to shuffle the data efficiently\n","def get_data(shards):\n","  dataset = tf.data.TFRecordDataset(shards)\n","  \n","\n","  dataset=dataset.map(parse_example)\n","  #dataset=dataset.repeat(1000)\n","  dataset=dataset.batch(1)\n","  data=iter(dataset)\n","  #data=dataset.as_numpy_iterator()\n","  return data\n","#.shuffle(100)"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3117,"status":"ok","timestamp":1651286320689,"user":{"displayName":"Mohamed Magdy","userId":"08172732745582365979"},"user_tz":-120},"id":"mGFMWrWjHp9W","outputId":"99be2e0f-6a29-4ddd-9ec1-9bac3d533bd8"},"outputs":[],"source":["train_dataset=get_data(train_shards)\n","test_dataset=get_data(test_shards)\n","val_dataset=get_data(val_shards)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":292,"status":"ok","timestamp":1650668080857,"user":{"displayName":"Mohamed Magdy","userId":"08172732745582365979"},"user_tz":-120},"id":"dH6HmXCr7yOo","outputId":"0dedd590-f725-41e8-8270-043896afcb36"},"outputs":[{"data":{"text/plain":["<tensorflow.python.data.ops.iterator_ops.OwnedIterator at 0x2aa9578fe80>"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["train_dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":274,"status":"ok","timestamp":1650668489556,"user":{"displayName":"Mohamed Magdy","userId":"08172732745582365979"},"user_tz":-120},"id":"V3herdNrgKAf","outputId":"97165803-51b7-4847-dedf-6bf27e8c3675"},"outputs":[{"data":{"text/plain":["(tf.float32, tf.int64)"]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["tf.compat.v1.data.get_output_types(train_dataset)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":286,"status":"ok","timestamp":1650668485802,"user":{"displayName":"Mohamed Magdy","userId":"08172732745582365979"},"user_tz":-120},"id":"W97L411rO-bL","outputId":"483a2709-9ba8-4ae4-aae9-2bd1e98a9e12"},"outputs":[{"data":{"text/plain":["(TensorShape([None, None, None, None, None]), TensorShape([None]))"]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["tf.compat.v1.data.get_output_shapes(train_dataset)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":298,"status":"ok","timestamp":1650668496381,"user":{"displayName":"Mohamed Magdy","userId":"08172732745582365979"},"user_tz":-120},"id":"x8HaGiouPPnV","outputId":"7d125139-fc86-4a36-8c6e-bc1c4293cbf4"},"outputs":[{"data":{"text/plain":["(tensorflow.python.framework.ops.Tensor,\n"," tensorflow.python.framework.ops.Tensor,\n"," tensorflow.python.framework.ops.Tensor)"]},"execution_count":25,"metadata":{},"output_type":"execute_result"}],"source":["tf.compat.v1.data.get_output_classes(dataset)\n"]},{"cell_type":"markdown","metadata":{},"source":["# OLD Model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fhp7CwjBbhmr"},"outputs":[],"source":["initial_learning_rate = 0.01\n","lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n","    initial_learning_rate, decay_steps=20, decay_rate=0.96, staircase=True\n",")\n","\n","checkpoint_cb = tf.keras.callbacks.ModelCheckpoint(\n","    \"signlanguage.h5\", save_best_only=True\n",")\n","\n","early_stopping_cb = tf.keras.callbacks.EarlyStopping(\n","    patience=10, restore_best_weights=True\n",")\n","def create_model():\n","    model=Sequential()\n","    model.add(Input((None,224, 224, 3)))\n","    #model.add(Flatten())\n","\n","    model.add(Conv3D(filters = 64, kernel_size = (1,3, 3), activation = 'relu'))\n","    model.add(Conv3D(filters = 64, kernel_size = (1,3, 3), activation = 'relu'))\n","    model.add(BatchNormalization())\n","    model.add(MaxPooling3D(pool_size = (1,2, 2)))\n","    model.add(GlobalAveragePooling3D())\n","    model.add(Dense(256, activation = 'relu'))\n","    model.add(BatchNormalization())\n","    model.add(Dense(2, activation = 'softmax'))\n","\n","    model.summary()\n","\n","    return model\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cBxBcFkw1bcJ"},"outputs":[],"source":["initial_learning_rate = 0.01\n","lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n","    initial_learning_rate, decay_steps=20, decay_rate=0.96, staircase=True\n",")\n","\n","checkpoint_cb = tf.keras.callbacks.ModelCheckpoint(\n","    \"signlanguage.h5\", save_best_only=True\n",")\n","\n","early_stopping_cb = tf.keras.callbacks.EarlyStopping(\n","    patience=10, restore_best_weights=True\n",")\n","def get_model(width=224, height=224, depth=None):\n","    \"\"\"Build a 3D convolutional neural network model.\"\"\"\n","\n","    inputs = Input((depth,height, width,  3))\n","\n","    x = Conv3D(filters=64, kernel_size=3, activation=\"relu\")(inputs)\n","    x = MaxPool3D(pool_size=2)(x)\n","    x = BatchNormalization()(x)\n","\n","    x = Conv3D(filters=64, kernel_size=3, activation=\"relu\")(x)\n","    x = MaxPool3D(pool_size=2)(x)\n","    x = BatchNormalization()(x)\n","\n","    x = Conv3D(filters=128, kernel_size=3, activation=\"relu\")(x)\n","    x = MaxPool3D(pool_size=2)(x)\n","    x = BatchNormalization()(x)\n","\n","    x = Conv3D(filters=256, kernel_size=3, activation=\"relu\")(x)\n","    x = MaxPool3D(pool_size=2)(x)\n","    x = BatchNormalization()(x)\n","    #x=Flatten()(x)\n","\n","    #x = GlobalAveragePooling3D()(x)\n","    #x = Dense(units=512, activation=\"relu\")(x)\n","    #x = Dropout(0.3)(x)\n","    x=Bidirectional(ConvLSTM2D(512,kernel_size=3))(x)\n","    \n","\n","    outputs = Dense(units=2, activation=\"sigmoid\")(x)\n","\n","    # Define the model.\n","    model = Model(inputs, outputs, name=\"3dcnn\")\n","    model.summary()\n","    return model\n"]},{"cell_type":"markdown","metadata":{},"source":["# MoVi net\n"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[],"source":["\n","batch_size = 8\n","num_frames = 8\n","frame_stride = 10\n","resolution = 172"]},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n"]},{"name":"stderr","output_type":"stream","text":["WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n"]},{"name":"stdout","output_type":"stream","text":["WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root)._save_counter\n"]},{"name":"stderr","output_type":"stream","text":["WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root)._save_counter\n"]},{"name":"stdout","output_type":"stream","text":["Model: \"movinet_classifier\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," image (InputLayer)          [(None, None, None, None  0         \n","                             , 3)]                               \n","                                                                 \n"," movinet (Movinet)           ({'stem': (None, None, N  911583    \n","                             one, None, 8),                      \n","                              'block0_layer0': (None,            \n","                              None, None, None, 8),              \n","                              'block1_layer0': (None,            \n","                              None, None, None, 32),             \n","                              'block1_layer1': (None,            \n","                              None, None, None, 32),             \n","                              'block1_layer2': (None,            \n","                              None, None, None, 32),             \n","                              'block2_layer0': (None,            \n","                              None, None, None, 56),             \n","                              'block2_layer1': (None,            \n","                              None, None, None, 56),             \n","                              'block2_layer2': (None,            \n","                              None, None, None, 56),             \n","                              'block3_layer0': (None,            \n","                              None, None, None, 56),             \n","                              'block3_layer1': (None,            \n","                              None, None, None, 56),             \n","                              'block3_layer2': (None,            \n","                              None, None, None, 56),             \n","                              'block3_layer3': (None,            \n","                              None, None, None, 56),             \n","                              'block4_layer0': (None,            \n","                              None, None, None, 104),            \n","                              'block4_layer1': (None,            \n","                              None, None, None, 104),            \n","                              'block4_layer2': (None,            \n","                              None, None, None, 104),            \n","                              'block4_layer3': (None,            \n","                              None, None, None, 104),            \n","                              'head': (None, None, No            \n","                             ne, None, 480)},                    \n","                              {'state_block0_layer0_p            \n","                             ool_buffer': (None, None            \n","                             , None, None, 24),                  \n","                              'state_block0_layer0_po            \n","                             ol_frame_count': (1,),              \n","                              'state_block1_layer0_po            \n","                             ol_buffer': (None, None,            \n","                              None, None, 80),                   \n","                              'state_block1_layer0_po            \n","                             ol_frame_count': (1,),              \n","                              'state_block1_layer1_po            \n","                             ol_buffer': (None, None,            \n","                              None, None, 80),                   \n","                              'state_block1_layer1_po            \n","                             ol_frame_count': (1,),              \n","                              'state_block1_layer2_po            \n","                             ol_buffer': (None, None,            \n","                              None, None, 80),                   \n","                              'state_block1_layer2_po            \n","                             ol_frame_count': (1,),              \n","                              'state_block2_layer0_po            \n","                             ol_buffer': (None, None,            \n","                              None, None, 184),                  \n","                              'state_block2_layer0_po            \n","                             ol_frame_count': (1,),              \n","                              'state_block2_layer1_po            \n","                             ol_buffer': (None, None,            \n","                              None, None, 112),                  \n","                              'state_block2_layer1_po            \n","                             ol_frame_count': (1,),              \n","                              'state_block2_layer2_po            \n","                             ol_buffer': (None, None,            \n","                              None, None, 184),                  \n","                              'state_block2_layer2_po            \n","                             ol_frame_count': (1,),              \n","                              'state_block3_layer0_po            \n","                             ol_buffer': (None, None,            \n","                              None, None, 184),                  \n","                              'state_block3_layer0_po            \n","                             ol_frame_count': (1,),              \n","                              'state_block3_layer1_po            \n","                             ol_buffer': (None, None,            \n","                              None, None, 184),                  \n","                              'state_block3_layer1_po            \n","                             ol_frame_count': (1,),              \n","                              'state_block3_layer2_po            \n","                             ol_buffer': (None, None,            \n","                              None, None, 184),                  \n","                              'state_block3_layer2_po            \n","                             ol_frame_count': (1,),              \n","                              'state_block3_layer3_po            \n","                             ol_buffer': (None, None,            \n","                              None, None, 184),                  \n","                              'state_block3_layer3_po            \n","                             ol_frame_count': (1,),              \n","                              'state_block4_layer0_po            \n","                             ol_buffer': (None, None,            \n","                              None, None, 384),                  \n","                              'state_block4_layer0_po            \n","                             ol_frame_count': (1,),              \n","                              'state_block4_layer1_po            \n","                             ol_buffer': (None, None,            \n","                              None, None, 280),                  \n","                              'state_block4_layer1_po            \n","                             ol_frame_count': (1,),              \n","                              'state_block4_layer2_po            \n","                             ol_buffer': (None, None,            \n","                              None, None, 280),                  \n","                              'state_block4_layer2_po            \n","                             ol_frame_count': (1,),              \n","                              'state_block4_layer3_po            \n","                             ol_buffer': (None, None,            \n","                              None, None, 344),                  \n","                              'state_block4_layer3_po            \n","                             ol_frame_count': (1,),              \n","                              'state_head_pool_buffer            \n","                             ': (None, None, None, No            \n","                             ne, 480),                           \n","                              'state_head_pool_frame_            \n","                             count': (1,)})                      \n","                                                                 \n"," classifier_head (Classifier  (None, 600)              2214488   \n"," Head)                                                           \n","                                                                 \n","=================================================================\n","Total params: 3,126,071\n","Trainable params: 3,111,799\n","Non-trainable params: 14,272\n","_________________________________________________________________\n"]}],"source":["model_id = 'a0'\n","\n","tf.keras.backend.clear_session()\n","\n","backbone = movinet.Movinet(model_id=model_id)\n","model = movinet_model.MovinetClassifier(backbone=backbone, num_classes=600)\n","model.build([1, 1, 1, 1, 3])\n","\n","# Load pretrained weights\n","#!wget https://storage.googleapis.com/tf_model_garden/vision/movinet/movinet_a0_base.tar.gz -O movinet_a0_base.tar.gz -q\n","!tar -xvf movinet_a0_base.tar.gz\n","\n","checkpoint_dir = 'movinet_a0_base'\n","checkpoint_path = tf.train.latest_checkpoint(checkpoint_dir)\n","checkpoint = tf.train.Checkpoint(model=model)\n","status = checkpoint.restore(checkpoint_path)\n","status.assert_existing_objects_matched()\n","model.summary()"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," keras_layer (KerasLayer)    (None, 600)               3126071   \n","                                                                 \n"," dense (Dense)               (None, 50)                30050     \n","                                                                 \n","=================================================================\n","Total params: 3,156,121\n","Trainable params: 30,050\n","Non-trainable params: 3,126,071\n","_________________________________________________________________\n"]}],"source":["def build_classifier(backbone, num_classes, freeze_backbone=False):\n","  \"\"\"Builds a classifier on top of a backbone model.\"\"\"\n","  model = movinet_model.MovinetClassifier(\n","      backbone=backbone,\n","      num_classes=num_classes)\n","  model.build([batch_size, num_frames, resolution, resolution, 3])\n","  if freeze_backbone:\n","    for layer in model.layers[:-1]:\n","      layer.trainable = False\n","    model.layers[-1].trainable = True\n","  \n","  \n","  return model\n","\n","\n","\n","# Wrap the backbone with a new classifier to create a new classifier head\n","# with num_classes outputs (101 classes for UCF101).\n","# Freeze all layers except for the final classifier head.\n","num_classes=1\n","\n","#model = build_classifier(backbone, num_classes, freeze_backbone=True)\n","for l in model.layers[:-1]:\n","  l.trainable=False\n","\n","model.layers[-1].trainable=True\n","model =hub.KerasLayer(model,input_shape=[None,None,None,3])\n","\n","\n","model=Sequential([model,Dense(50,activation='softmax')])\n","\n","model.summary()"]},{"cell_type":"code","execution_count":18,"metadata":{},"outputs":[{"ename":"TypeError","evalue":"call() missing 1 required positional argument: 'inputs'","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[1;32md:\\final final code\\records train.ipynb Cell 18'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/final%20final%20code/records%20train.ipynb#ch0000028?line=0'>1</a>\u001b[0m \u001b[39mfor\u001b[39;00m l \u001b[39min\u001b[39;00m model\u001b[39m.\u001b[39mlayers[:]:\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/final%20final%20code/records%20train.ipynb#ch0000028?line=1'>2</a>\u001b[0m     \u001b[39mprint\u001b[39m(l\u001b[39m.\u001b[39;49mcall())\n","\u001b[1;31mTypeError\u001b[0m: call() missing 1 required positional argument: 'inputs'"]}],"source":[]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[],"source":["num_epochs = 3\n","\n","train_steps = 720 // batch_size\n","total_train_steps = train_steps * num_epochs\n","test_steps = 450 // batch_size\n","\n","loss_obj = tf.keras.losses.CategoricalCrossentropy(\n","    from_logits=True,\n","    label_smoothing=0.1)\n","\n","metrics = [\n","    tf.keras.metrics.TopKCategoricalAccuracy(\n","        k=1, name='top_1', dtype=tf.float32),\n","    tf.keras.metrics.TopKCategoricalAccuracy(\n","        k=5, name='top_5', dtype=tf.float32),\n","]\n","\n","initial_learning_rate = 0.01\n","learning_rate = tf.keras.optimizers.schedules.CosineDecay(\n","    initial_learning_rate, decay_steps=total_train_steps,\n",")\n","optimizer = tf.keras.optimizers.RMSprop(\n","    learning_rate, rho=0.9, momentum=0.9, epsilon=1.0, clipnorm=1.0)\n","\n","model.compile(loss=loss_obj, optimizer=optimizer, metrics=metrics)\n","\n","callbacks = [\n","    tf.keras.callbacks.TensorBoard(),\n","]"]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["WARNING:tensorflow:Model failed to serialize as JSON. Ignoring... Can only generate a valid config for `hub.KerasLayer(handle, ...)`that uses a string `handle`.\n","\n","Got `type(handle)`: <class 'official.projects.movinet.modeling.movinet_model.MovinetClassifier'>\n"]},{"name":"stderr","output_type":"stream","text":["WARNING:tensorflow:Model failed to serialize as JSON. Ignoring... Can only generate a valid config for `hub.KerasLayer(handle, ...)`that uses a string `handle`.\n","\n","Got `type(handle)`: <class 'official.projects.movinet.modeling.movinet_model.MovinetClassifier'>\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 1/3\n"]},{"ename":"ValueError","evalue":"in user code:\n\n    File \"d:\\final final code\\env\\lib\\site-packages\\keras\\engine\\training.py\", line 1021, in train_function  *\n        return step_function(self, iterator)\n    File \"d:\\final final code\\env\\lib\\site-packages\\keras\\engine\\training.py\", line 1010, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"d:\\final final code\\env\\lib\\site-packages\\keras\\engine\\training.py\", line 1000, in run_step  **\n        outputs = model.train_step(data)\n    File \"d:\\final final code\\env\\lib\\site-packages\\keras\\engine\\training.py\", line 860, in train_step\n        loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"d:\\final final code\\env\\lib\\site-packages\\keras\\engine\\training.py\", line 918, in compute_loss\n        return self.compiled_loss(\n    File \"d:\\final final code\\env\\lib\\site-packages\\keras\\engine\\compile_utils.py\", line 201, in __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"d:\\final final code\\env\\lib\\site-packages\\keras\\losses.py\", line 141, in __call__\n        losses = call_fn(y_true, y_pred)\n    File \"d:\\final final code\\env\\lib\\site-packages\\keras\\losses.py\", line 245, in call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"d:\\final final code\\env\\lib\\site-packages\\keras\\losses.py\", line 1789, in categorical_crossentropy\n        return backend.categorical_crossentropy(\n    File \"d:\\final final code\\env\\lib\\site-packages\\keras\\backend.py\", line 5083, in categorical_crossentropy\n        target.shape.assert_is_compatible_with(output.shape)\n\n    ValueError: Shapes (None, 1) and (None, 50) are incompatible\n","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[1;32md:\\final final code\\records train.ipynb Cell 19'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/final%20final%20code/records%20train.ipynb#ch0000017?line=0'>1</a>\u001b[0m results \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mfit(\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/final%20final%20code/records%20train.ipynb#ch0000017?line=1'>2</a>\u001b[0m     train_dataset,\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/final%20final%20code/records%20train.ipynb#ch0000017?line=2'>3</a>\u001b[0m     validation_data\u001b[39m=\u001b[39;49mval_dataset,\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/final%20final%20code/records%20train.ipynb#ch0000017?line=3'>4</a>\u001b[0m     epochs\u001b[39m=\u001b[39;49mnum_epochs,\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/final%20final%20code/records%20train.ipynb#ch0000017?line=4'>5</a>\u001b[0m     steps_per_epoch\u001b[39m=\u001b[39;49mtrain_steps,\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/final%20final%20code/records%20train.ipynb#ch0000017?line=5'>6</a>\u001b[0m     validation_steps\u001b[39m=\u001b[39;49mtest_steps,\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/final%20final%20code/records%20train.ipynb#ch0000017?line=6'>7</a>\u001b[0m     callbacks\u001b[39m=\u001b[39;49mcallbacks,\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/final%20final%20code/records%20train.ipynb#ch0000017?line=7'>8</a>\u001b[0m     validation_freq\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m,\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/final%20final%20code/records%20train.ipynb#ch0000017?line=8'>9</a>\u001b[0m     verbose\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m)\n","File \u001b[1;32md:\\final final code\\env\\lib\\site-packages\\keras\\utils\\traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     <a href='file:///d%3A/final%20final%20code/env/lib/site-packages/keras/utils/traceback_utils.py?line=64'>65</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     <a href='file:///d%3A/final%20final%20code/env/lib/site-packages/keras/utils/traceback_utils.py?line=65'>66</a>\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m---> <a href='file:///d%3A/final%20final%20code/env/lib/site-packages/keras/utils/traceback_utils.py?line=66'>67</a>\u001b[0m   \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[0;32m     <a href='file:///d%3A/final%20final%20code/env/lib/site-packages/keras/utils/traceback_utils.py?line=67'>68</a>\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     <a href='file:///d%3A/final%20final%20code/env/lib/site-packages/keras/utils/traceback_utils.py?line=68'>69</a>\u001b[0m   \u001b[39mdel\u001b[39;00m filtered_tb\n","File \u001b[1;32md:\\final final code\\env\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py:1147\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func.<locals>.autograph_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   <a href='file:///d%3A/final%20final%20code/env/lib/site-packages/tensorflow/python/framework/func_graph.py?line=1144'>1145</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint:disable=broad-except\u001b[39;00m\n\u001b[0;32m   <a href='file:///d%3A/final%20final%20code/env/lib/site-packages/tensorflow/python/framework/func_graph.py?line=1145'>1146</a>\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(e, \u001b[39m\"\u001b[39m\u001b[39mag_error_metadata\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m-> <a href='file:///d%3A/final%20final%20code/env/lib/site-packages/tensorflow/python/framework/func_graph.py?line=1146'>1147</a>\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mag_error_metadata\u001b[39m.\u001b[39mto_exception(e)\n\u001b[0;32m   <a href='file:///d%3A/final%20final%20code/env/lib/site-packages/tensorflow/python/framework/func_graph.py?line=1147'>1148</a>\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   <a href='file:///d%3A/final%20final%20code/env/lib/site-packages/tensorflow/python/framework/func_graph.py?line=1148'>1149</a>\u001b[0m     \u001b[39mraise\u001b[39;00m\n","\u001b[1;31mValueError\u001b[0m: in user code:\n\n    File \"d:\\final final code\\env\\lib\\site-packages\\keras\\engine\\training.py\", line 1021, in train_function  *\n        return step_function(self, iterator)\n    File \"d:\\final final code\\env\\lib\\site-packages\\keras\\engine\\training.py\", line 1010, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"d:\\final final code\\env\\lib\\site-packages\\keras\\engine\\training.py\", line 1000, in run_step  **\n        outputs = model.train_step(data)\n    File \"d:\\final final code\\env\\lib\\site-packages\\keras\\engine\\training.py\", line 860, in train_step\n        loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"d:\\final final code\\env\\lib\\site-packages\\keras\\engine\\training.py\", line 918, in compute_loss\n        return self.compiled_loss(\n    File \"d:\\final final code\\env\\lib\\site-packages\\keras\\engine\\compile_utils.py\", line 201, in __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"d:\\final final code\\env\\lib\\site-packages\\keras\\losses.py\", line 141, in __call__\n        losses = call_fn(y_true, y_pred)\n    File \"d:\\final final code\\env\\lib\\site-packages\\keras\\losses.py\", line 245, in call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"d:\\final final code\\env\\lib\\site-packages\\keras\\losses.py\", line 1789, in categorical_crossentropy\n        return backend.categorical_crossentropy(\n    File \"d:\\final final code\\env\\lib\\site-packages\\keras\\backend.py\", line 5083, in categorical_crossentropy\n        target.shape.assert_is_compatible_with(output.shape)\n\n    ValueError: Shapes (None, 1) and (None, 50) are incompatible\n"]}],"source":["results = model.fit(\n","    train_dataset,\n","    validation_data=val_dataset,\n","    epochs=num_epochs,\n","    steps_per_epoch=train_steps,\n","    validation_steps=test_steps,\n","    callbacks=callbacks,\n","    validation_freq=1,\n","    verbose=1)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7331,"status":"ok","timestamp":1651287099297,"user":{"displayName":"Mohamed Magdy","userId":"08172732745582365979"},"user_tz":-120},"id":"qLkLtljdMPEx","outputId":"02e7d77e-36fb-41c9-b22b-b103adc690c0"},"outputs":[{"name":"stdout","output_type":"stream","text":["Model: \"3dcnn\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_7 (InputLayer)        [(None, None, 224, 224,   0         \n","                             3)]                                 \n","                                                                 \n"," conv3d_24 (Conv3D)          (None, None, 222, 222, 6  5248      \n","                             4)                                  \n","                                                                 \n"," max_pooling3d_24 (MaxPoolin  (None, None, 111, 111, 6  0        \n"," g3D)                        4)                                  \n","                                                                 \n"," batch_normalization_24 (Bat  (None, None, 111, 111, 6  256      \n"," chNormalization)            4)                                  \n","                                                                 \n"," conv3d_25 (Conv3D)          (None, None, 109, 109, 6  110656    \n","                             4)                                  \n","                                                                 \n"," max_pooling3d_25 (MaxPoolin  (None, None, 54, 54, 64)  0        \n"," g3D)                                                            \n","                                                                 \n"," batch_normalization_25 (Bat  (None, None, 54, 54, 64)  256      \n"," chNormalization)                                                \n","                                                                 \n"," conv3d_26 (Conv3D)          (None, None, 52, 52, 128  221312    \n","                             )                                   \n","                                                                 \n"," max_pooling3d_26 (MaxPoolin  (None, None, 26, 26, 128  0        \n"," g3D)                        )                                   \n","                                                                 \n"," batch_normalization_26 (Bat  (None, None, 26, 26, 128  512      \n"," chNormalization)            )                                   \n","                                                                 \n"," conv3d_27 (Conv3D)          (None, None, 24, 24, 256  884992    \n","                             )                                   \n","                                                                 \n"," max_pooling3d_27 (MaxPoolin  (None, None, 12, 12, 256  0        \n"," g3D)                        )                                   \n","                                                                 \n"," batch_normalization_27 (Bat  (None, None, 12, 12, 256  1024     \n"," chNormalization)            )                                   \n","                                                                 \n"," bidirectional_5 (Bidirectio  (None, 10, 10, 1024)     28315648  \n"," nal)                                                            \n","                                                                 \n"," dense_2 (Dense)             (None, 10, 10, 2)         2050      \n","                                                                 \n","=================================================================\n","Total params: 29,541,954\n","Trainable params: 29,540,930\n","Non-trainable params: 1,024\n","_________________________________________________________________\n"]}],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AfrDPKtrdir3"},"outputs":[],"source":["model.compile(optimizer='adam',loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), metrics=['accuracy'])\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":33693,"status":"error","timestamp":1651287151376,"user":{"displayName":"Mohamed Magdy","userId":"08172732745582365979"},"user_tz":-120},"id":"-DxmoGlLcwtM","outputId":"713e54b9-0308-43b9-efcb-2de5da850b45"},"outputs":[],"source":["history=model.fit(dataset ,epochs=10,batch_size=32 ,steps_per_epoch=100)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"072qemKxdaJh"},"outputs":[],"source":["tf.keras.utils.plot_model(model, show_dtype=True, show_shapes=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"R5IuiO497IS2"},"outputs":[],"source":["\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pHFgE9v0q1pU"},"outputs":[],"source":["# Install packages\n","\n","# tf-models-official is the stable Model Garden package\n","# tf-models-nightly includes latest changes\n","!pip install -q tf-models-official\n","\n","# Install the mediapy package for visualizing images/videos.\n","# See https://github.com/google/mediapy\n","#!command -v ffmpeg >/dev/null || (apt update && apt install -y ffmpeg)\n","!pip install -q mediapy\n","\n","# Due to a bug, we reinstall opencv\n","# See https://stackoverflow.com/q/70537488\n","!pip uninstall -q -y opencv-python-headless\n","!pip install -q \"opencv-python-headless>4.3\""]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["ERROR: unknown command \"numpy\"\n","\n"]}],"source":["!pip numpy --version\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting numpy\n","  Downloading numpy-1.22.3-cp38-cp38-win_amd64.whl (14.7 MB)\n","Installing collected packages: numpy\n","  Attempting uninstall: numpy\n","    Found existing installation: numpy 1.18.5\n","    Uninstalling numpy-1.18.5:\n","      Successfully uninstalled numpy-1.18.5\n","Successfully installed numpy-1.22.3\n"]}],"source":["!pip install numpy --upgrade\n"," "]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyMs8UcM45jz3Nupu4RGUa2L","collapsed_sections":[],"mount_file_id":"1tFuP-2f0U7J6s-ZrsJuX5r6OoaI0rJjN","name":"records train.ipynb","provenance":[]},"interpreter":{"hash":"0ba905e921388c990706aa39af2c2bb80c4fd211c17e442f1484722385a96b46"},"kernelspec":{"display_name":"Python 3.9.6 ('env': venv)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.6"}},"nbformat":4,"nbformat_minor":0}
